{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**NAME : ABHINAV KRISHNA B**"
      ],
      "metadata": {
        "id": "IxLwqpMq-IJM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**IMPORT LIBRARIES AND LOAD TRAIN , TEST DATASET**"
      ],
      "metadata": {
        "id": "31pIMa7S-M1i"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gLgAwNmyx81K",
        "outputId": "7403a757-a92a-450e-9e31-35d511180b70"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Unnamed: 0 trans_date_trans_time            cc_num  \\\n",
            "0           0   2019-01-01 00:00:18  2703186189652095   \n",
            "1           1   2019-01-01 00:00:44      630423337322   \n",
            "2           2   2019-01-01 00:00:51    38859492057661   \n",
            "3           3   2019-01-01 00:01:16  3534093764340240   \n",
            "4           4   2019-01-01 00:03:06   375534208663984   \n",
            "\n",
            "                             merchant       category     amt      first  \\\n",
            "0          fraud_Rippin, Kub and Mann       misc_net    4.97   Jennifer   \n",
            "1     fraud_Heller, Gutmann and Zieme    grocery_pos  107.23  Stephanie   \n",
            "2                fraud_Lind-Buckridge  entertainment  220.11     Edward   \n",
            "3  fraud_Kutch, Hermiston and Farrell  gas_transport   45.00     Jeremy   \n",
            "4                 fraud_Keeling-Crist       misc_pos   41.96      Tyler   \n",
            "\n",
            "      last gender                        street  ...      lat      long  \\\n",
            "0    Banks      F                561 Perry Cove  ...  36.0788  -81.1781   \n",
            "1     Gill      F  43039 Riley Greens Suite 393  ...  48.8878 -118.2105   \n",
            "2  Sanchez      M      594 White Dale Suite 530  ...  42.1808 -112.2620   \n",
            "3    White      M   9443 Cynthia Court Apt. 038  ...  46.2306 -112.1138   \n",
            "4   Garcia      M              408 Bradley Rest  ...  38.4207  -79.4629   \n",
            "\n",
            "   city_pop                                job         dob  \\\n",
            "0      3495          Psychologist, counselling  1988-03-09   \n",
            "1       149  Special educational needs teacher  1978-06-21   \n",
            "2      4154        Nature conservation officer  1962-01-19   \n",
            "3      1939                    Patent attorney  1967-01-12   \n",
            "4        99     Dance movement psychotherapist  1986-03-28   \n",
            "\n",
            "                          trans_num   unix_time  merch_lat  merch_long  \\\n",
            "0  0b242abb623afc578575680df30655b9  1325376018  36.011293  -82.048315   \n",
            "1  1f76529f8574734946361c461b024d99  1325376044  49.159047 -118.186462   \n",
            "2  a1a22d70485983eac12b5b88dad1cf95  1325376051  43.150704 -112.154481   \n",
            "3  6b849c168bdad6f867558c3793159a81  1325376076  47.034331 -112.561071   \n",
            "4  a41d7549acf90789359a9aa5346dcb46  1325376186  38.674999  -78.632459   \n",
            "\n",
            "   is_fraud  \n",
            "0         0  \n",
            "1         0  \n",
            "2         0  \n",
            "3         0  \n",
            "4         0  \n",
            "\n",
            "[5 rows x 23 columns]\n",
            "   Unnamed: 0 trans_date_trans_time            cc_num  \\\n",
            "0           0   2020-06-21 12:14:25  2291163933867244   \n",
            "1           1   2020-06-21 12:14:33  3573030041201292   \n",
            "2           2   2020-06-21 12:14:53  3598215285024754   \n",
            "3           3   2020-06-21 12:15:15  3591919803438423   \n",
            "4           4   2020-06-21 12:15:17  3526826139003047   \n",
            "\n",
            "                               merchant        category    amt   first  \\\n",
            "0                 fraud_Kirlin and Sons   personal_care   2.86    Jeff   \n",
            "1                  fraud_Sporer-Keebler   personal_care  29.84  Joanne   \n",
            "2  fraud_Swaniawski, Nitzsche and Welch  health_fitness  41.28  Ashley   \n",
            "3                     fraud_Haley Group        misc_pos  60.05   Brian   \n",
            "4                 fraud_Johnston-Casper          travel   3.19  Nathan   \n",
            "\n",
            "       last gender                       street  ...      lat      long  \\\n",
            "0   Elliott      M            351 Darlene Green  ...  33.9659  -80.9355   \n",
            "1  Williams      F             3638 Marsh Union  ...  40.3207 -110.4360   \n",
            "2     Lopez      F         9333 Valentine Point  ...  40.6729  -73.5365   \n",
            "3  Williams      M  32941 Krystal Mill Apt. 552  ...  28.5697  -80.8191   \n",
            "4    Massey      M     5783 Evan Roads Apt. 465  ...  44.2529  -85.0170   \n",
            "\n",
            "   city_pop                     job         dob  \\\n",
            "0    333497     Mechanical engineer  1968-03-19   \n",
            "1       302  Sales professional, IT  1990-01-17   \n",
            "2     34496       Librarian, public  1970-10-21   \n",
            "3     54767            Set designer  1987-07-25   \n",
            "4      1126      Furniture designer  1955-07-06   \n",
            "\n",
            "                          trans_num   unix_time  merch_lat  merch_long  \\\n",
            "0  2da90c7d74bd46a0caf3777415b3ebd3  1371816865  33.986391  -81.200714   \n",
            "1  324cc204407e99f51b0d6ca0055005e7  1371816873  39.450498 -109.960431   \n",
            "2  c81755dbbbea9d5c77f094348a7579be  1371816893  40.495810  -74.196111   \n",
            "3  2159175b9efe66dc301f149d3d5abf8c  1371816915  28.812398  -80.883061   \n",
            "4  57ff021bd3f328f8738bb535c302a31b  1371816917  44.959148  -85.884734   \n",
            "\n",
            "   is_fraud  \n",
            "0         0  \n",
            "1         0  \n",
            "2         0  \n",
            "3         0  \n",
            "4         0  \n",
            "\n",
            "[5 rows x 23 columns]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the training and test datasets\n",
        "train_df = pd.read_csv('/content/drive/MyDrive/fraudTrain.csv')\n",
        "test_df = pd.read_csv('/content/drive/MyDrive/fraudTest.csv')\n",
        "\n",
        "# Explore the data\n",
        "print(train_df.head())\n",
        "print(test_df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "0ccqSkaT-UE1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DROP UNNECCESARY COLUMNS FOR PREDICTION**"
      ],
      "metadata": {
        "id": "34ygbec4-UOP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Drop columns that are not useful or have too many unique values in both datasets\n",
        "columns_to_drop = ['Unnamed: 0','cc_num','first', 'last', 'street', 'city', 'state', 'zip', 'trans_num','lat','long','city_pop','merch_lat','merch_long','unix_time']\n",
        "train_df = train_df.drop(columns_to_drop, axis=1)\n",
        "test_df = test_df.drop(columns_to_drop, axis=1)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ywMAzNoo0g0P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DATA PREPROCESSING DATE-TIME EXTRACTION FROM DD-MM-YYYY FORMAT**"
      ],
      "metadata": {
        "id": "2OhPL1rN-glK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert 'trans_date_trans_time' to datetime and extract features for both datasets\n",
        "for df in [train_df, test_df]:\n",
        "    df['trans_date_trans_time'] = pd.to_datetime(df['trans_date_trans_time'], format='%Y-%m-%d %H:%M:%S')\n",
        "    df['hour'] = df['trans_date_trans_time'].dt.hour\n",
        "    df['day'] = df['trans_date_trans_time'].dt.day\n",
        "    df['day_of_week'] = df['trans_date_trans_time'].dt.dayofweek\n",
        "    df['month'] = df['trans_date_trans_time'].dt.month\n",
        "    df['quarter'] = df['trans_date_trans_time'].dt.quarter\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Clean the dataframe by dropping unnecessary columns and handle 'merchant' column for both datasets\n",
        "def clean_df(df):\n",
        "    df = df.drop(['trans_date_trans_time', 'dob'], axis=1)\n",
        "    df['merchant'] = df['merchant'].apply(lambda x: x.replace('fraud_', ''))\n",
        "    return df\n",
        "\n",
        "train_df = clean_df(train_df)\n",
        "test_df = clean_df(test_df)\n",
        "\n"
      ],
      "metadata": {
        "id": "b4RbzI250vIG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CONVERTION OF CREDIT AMOUNT INTO SEGREGATED INTERVALS USING BINNING**"
      ],
      "metadata": {
        "id": "G2tga655-qy5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Bin the 'amt' column for both datasets\n",
        "num_bins = 300\n",
        "for df in [train_df, test_df]:\n",
        "    df['amt'] = pd.cut(df['amt'], bins=num_bins, labels=False, right=False)"
      ],
      "metadata": {
        "id": "nHPTmLvK2V5w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**MAP CATEGORICAL ATTRIBUTES TO BINARY FOR PREDICTION**"
      ],
      "metadata": {
        "id": "eh3yr1OG-ysA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def map_gender(df):\n",
        "    df['gender_M'] = df['gender'].apply(lambda x: 1 if x == 'M' else 0)\n",
        "    df['gender_F'] = df['gender'].apply(lambda x: 1 if x == 'F' else 0)\n",
        "    return df.drop(['gender'], axis=1)\n",
        "\n",
        "train_df = map_gender(train_df)\n",
        "test_df = map_gender(test_df)\n",
        "\n"
      ],
      "metadata": {
        "id": "Ulqduw1d2a7u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**LABEL ENCODING FOR STRING ATTRIBUTES LIKE MERCHANT,JOB AND CATEGORY OF CREDIT**"
      ],
      "metadata": {
        "id": "DuE3MI_S-5wP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "encoder = LabelEncoder()\n",
        "def encode(df):\n",
        "    df['merchant'] = encoder.fit_transform(df['merchant'])\n",
        "    df['category'] = encoder.fit_transform(df['category'])\n",
        "    df['job'] = encoder.fit_transform(df['job'])\n",
        "    return df\n",
        "\n",
        "train_df = encode(train_df)\n",
        "test_df = encode(test_df)"
      ],
      "metadata": {
        "id": "nSiJQFX122_i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DATASET AFTER PREPROCESSING**"
      ],
      "metadata": {
        "id": "l3scUO7V_F9o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_df.head())\n",
        "print(test_df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-PR7qZoS26JY",
        "outputId": "1aa9266c-ab41-4f1d-e07e-195f3ba86832"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   merchant  category  amt  job  is_fraud  hour  day  day_of_week  month  \\\n",
            "0       514         8    0  370         0     0    1            1      1   \n",
            "1       241         4    1  428         0     0    1            1      1   \n",
            "2       390         0    2  307         0     0    1            1      1   \n",
            "3       360         2    0  328         0     0    1            1      1   \n",
            "4       297         9    0  116         0     0    1            1      1   \n",
            "\n",
            "   quarter  gender_M  gender_F  \n",
            "0        1         0         1  \n",
            "1        1         0         1  \n",
            "2        1         1         0  \n",
            "3        1         1         0  \n",
            "4        1         1         0  \n",
            "   merchant  category  amt  job  is_fraud  hour  day  day_of_week  month  \\\n",
            "0       319        10    0  275         0    12   21            6      6   \n",
            "1       591        10    0  392         0    12   21            6      6   \n",
            "2       611         5    0  259         0    12   21            6      6   \n",
            "3       222         9    0  407         0    12   21            6      6   \n",
            "4       292        13    0  196         0    12   21            6      6   \n",
            "\n",
            "   quarter  gender_M  gender_F  \n",
            "0        2         1         0  \n",
            "1        2         0         1  \n",
            "2        2         0         1  \n",
            "3        2         1         0  \n",
            "4        2         1         0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**TRAINING AND TESTING SPLIT OF DATASET**"
      ],
      "metadata": {
        "id": "D23AqKgJ_JyE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the training data into features and target variable\n",
        "X_train = train_df.drop('is_fraud', axis=1)\n",
        "y_train = train_df['is_fraud']\n",
        "\n",
        "# Split the test data into features and target variable\n",
        "X_test = test_df.drop('is_fraud', axis=1)\n",
        "y_test = test_df['is_fraud']\n"
      ],
      "metadata": {
        "id": "2pk7Hv1w6Xg2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NORMALIZATION FOR BETTER ACCURACY**"
      ],
      "metadata": {
        "id": "IZ7NJnDu_Oy6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Normalize the data\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n"
      ],
      "metadata": {
        "id": "w2CLpmMK60xn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**MODEL TRANING AND TESTING PHASE LOGISTIC REGRESSION**"
      ],
      "metadata": {
        "id": "qIY3HUdo_UX3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "\n",
        "# Train Logistic Regression model\n",
        "lr_model = LogisticRegression()\n",
        "lr_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred_lr = lr_model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "print(\"Logistic Regression Results:\")\n",
        "print(confusion_matrix(y_test, y_pred_lr))\n",
        "print(classification_report(y_test, y_pred_lr))\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred_lr))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2G-Xa_207YZO",
        "outputId": "5dce365d-3005-4df0-bebc-2c2e2b98e249"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Results:\n",
            "[[553059    515]\n",
            " [  2145      0]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00    553574\n",
            "           1       0.00      0.00      0.00      2145\n",
            "\n",
            "    accuracy                           1.00    555719\n",
            "   macro avg       0.50      0.50      0.50    555719\n",
            "weighted avg       0.99      1.00      0.99    555719\n",
            "\n",
            "Accuracy: 0.995213408215303\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DECISION TREE CLASSIFIER**"
      ],
      "metadata": {
        "id": "ko4OZf5j_Zzz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Train Decision Tree model\n",
        "dt_model = DecisionTreeClassifier()\n",
        "dt_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred_dt = dt_model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "print(\"Decision Tree Results:\")\n",
        "print(confusion_matrix(y_test, y_pred_dt))\n",
        "print(classification_report(y_test, y_pred_dt))\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred_dt))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o4kRtXTQ7aKx",
        "outputId": "9ec85450-3300-4beb-fb38-66c9ce76e9f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree Results:\n",
            "[[550430   3144]\n",
            " [  1101   1044]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      1.00    553574\n",
            "           1       0.25      0.49      0.33      2145\n",
            "\n",
            "    accuracy                           0.99    555719\n",
            "   macro avg       0.62      0.74      0.66    555719\n",
            "weighted avg       1.00      0.99      0.99    555719\n",
            "\n",
            "Accuracy: 0.9923612473210381\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**RANDOM FOREST CLASSSIFIER**"
      ],
      "metadata": {
        "id": "jQdJP5gx_dsC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Train Random Forest model\n",
        "rf_model = RandomForestClassifier()\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred_rf = rf_model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "print(\"Random Forest Results:\")\n",
        "print(confusion_matrix(y_test, y_pred_rf))\n",
        "print(classification_report(y_test, y_pred_rf))\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred_rf))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nkvAbXQc7c9N",
        "outputId": "a6aead8d-889c-4e10-8b68-a228267188ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Results:\n",
            "[[552437   1137]\n",
            " [  1120   1025]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00    553574\n",
            "           1       0.47      0.48      0.48      2145\n",
            "\n",
            "    accuracy                           1.00    555719\n",
            "   macro avg       0.74      0.74      0.74    555719\n",
            "weighted avg       1.00      1.00      1.00    555719\n",
            "\n",
            "Accuracy: 0.9959385948653906\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CREATION OF PREDICTED FRAUD RATE INTO CSV FILE**"
      ],
      "metadata": {
        "id": "efFYy9dr_hEM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a DataFrame with the predictions\n",
        "test_df['is_fraud_pred'] = y_pred_rf\n",
        "\n",
        "# Save to CSV\n",
        "test_df[['is_fraud', 'is_fraud_pred']].to_csv('creditcard_test_predictions.csv', index=False)\n"
      ],
      "metadata": {
        "id": "sAetn-t87z3l"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}